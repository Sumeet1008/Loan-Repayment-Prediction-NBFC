# -*- coding: utf-8 -*-
"""model_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/109Ou8YJ3CsHvGlrBaoKSCAupgBSuuNa1
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split

# Use pd.read_excel to read Excel files
df1 = pd.read_excel('/content/drive/MyDrive/DSW/train_data.xlsx')
df1.shape

df2 = pd.read_excel('/content/drive/MyDrive/DSW/test_data.xlsx')
df2.shape

df = pd.concat((df1 , df2))
df.shape

df.head()

df.info()

transformer = ColumnTransformer(transformers=[
    ('tnf1',OneHotEncoder(sparse_output = False,drop='first'),['sub_grade' , 'term', 'home_ownership' , 'purpose' , 'application_type' , 'verification_status' ])
],remainder='passthrough')

x = df.iloc[: , 2:-1]
y = df['loan_status']

x.shape

x.head()

x_encode = transformer.fit_transform(x)

x_encode

x_encode.shape

x_train , x_test , y_train , y_test = train_test_split(x_encode , y , test_size = 0.2 , random_state = 42)

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# Initialize and train the model
rf_model = RandomForestClassifier(n_estimators=15 , max_depth = 16, min_samples_leaf = 4,max_features='sqrt',bootstrap=True, random_state=42)
rf_model.fit(x_train, y_train)

# Predictions
y_train_pred = rf_model.predict(x_train)
y_test_pred = rf_model.predict(x_test)

# Evaluation
print("Random Forest Accuracy (training):", accuracy_score(y_train, y_train_pred))
print("Random Forest Accuracy (testing):", accuracy_score(y_test, y_test_pred))
# print("Classification Report (testing):\n", classification_report(y_test, y_test_pred))

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

# Initialize and train the model
log_reg = LogisticRegression()
log_reg.fit(x_train, y_train)

# Predictions
y_train_pred = log_reg.predict(x_train)
y_test_pred = log_reg.predict(x_test)

# Evaluation
print("Logistic Regression Accuracy (training):", accuracy_score(y_train, y_train_pred))
print("Logistic Regression Accuracy (testing):", accuracy_score(y_test, y_test_pred))
print("Classification Report (testing):\n", classification_report(y_test, y_test_pred))

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

# Hyperparameter grid to search over
param_grid = {
    'C': [0.1, 1, 10, 100],  # Regularization strength
    'penalty': ['l2'],  # L2 regularization (you can try 'l1' or 'elasticnet')
    'solver': ['liblinear', 'lbfgs', 'newton-cg'],  # Solver options
    'max_iter': [100, 200, 300]  # Maximum number of iterations
}

# Initialize Logistic Regression model
log_reg = LogisticRegression()

# Initialize GridSearchCV
grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)

# Fit the model to the training data
grid_search.fit(x_train, y_train)

# Best hyperparameters found
print("Best Hyperparameters: ", grid_search.best_params_)

# Best model
best_model = grid_search.best_estimator_

# Predictions on the test set
y_pred = best_model.predict(x_test)

# Evaluation
print("Logistic Regression Accuracy (testing):", accuracy_score(y_test, y_pred)*100)

from xgboost import XGBClassifier
from sklearn.metrics import classification_report, accuracy_score

# Initialize and train the model
xgb_model = XGBClassifier(n_esimators = 2, use_label_encoder=False, eval_metric='logloss', random_state=4)
xgb_model.fit(x_train, y_train)

# Predictions
y_train_pred = xgb_model.predict(x_train)
y_test_pred = xgb_model.predict(x_test)

# Evaluation
print("XGBoost Accuracy (training):", accuracy_score(y_train, y_train_pred))
print("XGBoost Accuracy (testing):", accuracy_score(y_test, y_test_pred))
# print("Classification Report (testing):\n", classification_report(y_test, y_test_pred))